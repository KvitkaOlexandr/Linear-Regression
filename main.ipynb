{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\nDep. Variable:                   thal   R-squared:                       0.005\nModel:                            OLS   Adj. R-squared:                  0.001\nMethod:                 Least Squares   F-statistic:                     1.398\nDate:                Sat, 21 Dec 2019   Prob (F-statistic):              0.238\nTime:                        13:49:34   Log-Likelihood:                -280.09\nNo. Observations:                 303   AIC:                             564.2\nDf Residuals:                     301   BIC:                             571.6\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\n                 coef    std err          t      P\u003e|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      2.0643      0.214      9.661      0.000       1.644       2.485\nage            0.0046      0.004      1.183      0.238      -0.003       0.012\n\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\nOmnibus:                       13.410   Durbin-Watson:                   1.592\nProb(Omnibus):                  0.001   Jarque-Bera (JB):               13.910\nSkew:                          -0.499   Prob(JB):                     0.000954\nKurtosis:                       3.322   Cond. No.                         335.\n\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\n\nWarnings:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\nAccuracy of Logistic regression classifier on training set: 0.38\nAccuracy of Logistic regression classifier on test set: 0.41\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "\nimport pandas as pd\nimport statsmodels.formula.api as smapi\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.linear_model import LogisticRegression\n\n\nheart \u003d pd.read_csv(\u0027heart.csv\u0027)\nlm \u003d smapi.ols(formula\u003d\u0027thal~age\u0027, data\u003dheart).fit()\nprint(lm.summary())\n\nfeature_names \u003d [\u0027age\u0027, \u0027sex\u0027, \u0027cp\u0027, \u0027trestbps\u0027, \u0027chol\u0027, \u0027fbs\u0027, \u0027restecg\u0027, \u0027thalach\u0027, \u0027exang\u0027, \u0027oldpeak\u0027, \u0027slope\u0027, \u0027ca\u0027]\nx \u003d heart[feature_names]\ny \u003d heart[\u0027thal\u0027]\n\nx_train, x_test, y_train, y_test \u003d train_test_split(x, y, random_state\u003d0)\nscaler \u003d MinMaxScaler()\n\nX_train \u003d scaler.fit_transform(x_train)\nX_test \u003d scaler.transform(x_test)\n\nreg \u003d LogisticRegression()\nreg.fit(X_train, y_train)\n\nprint(\u0027Accuracy of Logistic regression classifier on training set: {:.2f}\u0027.format(reg.score(x_train, y_train)))\nprint(\u0027Accuracy of Logistic regression classifier on test set: {:.2f}\u0027.format(reg.score(x_test, y_test)))\n\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% code\n",
          "is_executing": false
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "stem_cell": {
      "cell_type": "raw",
      "source": "",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}